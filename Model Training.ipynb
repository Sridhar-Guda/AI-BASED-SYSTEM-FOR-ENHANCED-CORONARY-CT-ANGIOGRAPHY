{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7044e1",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a201e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import  MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16c5b3",
   "metadata": {},
   "source": [
    "# Define the path to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b68bf5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06267a62",
   "metadata": {},
   "source": [
    "# Initialize lists to store image data and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141b33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eea987",
   "metadata": {},
   "source": [
    "# Iterate through the dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645fa746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noplaque Dataset\\Noplaque/aug_0_1141.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_1258.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_1436.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_1451.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_2128.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_2248.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_2380.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_2413.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_260.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_3010.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_3634.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_3873.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_4299.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_439.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_4480.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_4710.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_5226.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_5301.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_5456.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_555.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_5929.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_5964.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_6362.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_652.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_6649.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_7706.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_8088.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_8409.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_8437.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_9128.png 0\n",
      "Noplaque Dataset\\Noplaque/aug_0_9293.png 0\n",
      "Plaque Dataset\\Plaque/aug_0_1128.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_1433.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_1488.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_1593.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_2044.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_2095.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_2672.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_2701.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_2874.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_3276.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_3501.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_4094.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_4274.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_430.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_4329.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_4339.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_4577.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_5103.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_5113.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_5717.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_5733.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_67.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_6736.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_7676.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_7855.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_848.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_8675.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_9216.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_9238.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_9795.png 1\n",
      "Plaque Dataset\\Plaque/aug_0_9969.png 1\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, directory in os.walk(path):\n",
    "    for j in range(len(directory)):\n",
    "        name = os.path.basename(root)\n",
    "        if 'Thumbs.db' not in directory[j]:\n",
    "            img = cv2.imread(root+\"/\"+directory[j])\n",
    "            img = cv2.resize(img, (64,64))\n",
    "            im2arr = np.array(img)\n",
    "            im2arr = im2arr.reshape(64,64,3)\n",
    "            X.append(im2arr)\n",
    "            lbl = 0\n",
    "            if name == 'Plaque':\n",
    "                lbl = 1\n",
    "            Y.append(lbl)\n",
    "            print(name+\" \"+root+\"/\"+directory[j]+\" \"+str(lbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c4ea2",
   "metadata": {},
   "source": [
    "# Convert lists to numpy arrays and Normalize the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc25c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays and Normalize the image data\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "X = X.astype('float32')\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb8b7b",
   "metadata": {},
   "source": [
    "# Shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee77c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "Y = Y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b4f76",
   "metadata": {},
   "source": [
    "# Convert labels to categorical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997e1370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical format\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d860898d",
   "metadata": {},
   "source": [
    "# Save and Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb5fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load preprocessed data\n",
    "np.save('model/X.txt', X)\n",
    "np.save('model/Y.txt', Y)\n",
    "X = np.load('model/X.txt.npy')\n",
    "Y = np.load('model/Y.txt.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a119d6",
   "metadata": {},
   "source": [
    "# Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b54f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2315f473",
   "metadata": {},
   "source": [
    "# Generate or Load RCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e62c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create a RCNN model\n",
    "if os.path.exists('model/model.json'):\n",
    "    # Load model from JSON and weights from H5 file\n",
    "    with open('model/model.json', \"r\") as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "        classifier = model_from_json(loaded_model_json)\n",
    "    json_file.close()\n",
    "    classifier.load_weights(\"model/model_weights.h5\")\n",
    "else:\n",
    "    # Create a new CNN model\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    classifier.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(output_dim=256, activation='relu'))\n",
    "    classifier.add(Dense(output_dim=Y.shape[1], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f91e3e6",
   "metadata": {},
   "source": [
    "# Print Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a985959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 31, 31, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               1605888   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1616546 (6.17 MB)\n",
      "Trainable params: 1616546 (6.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    " # Print model summary\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c537ec",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c64139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fda1fe",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d918d150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 - 2s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.1168e-06 - val_accuracy: 1.0000 - 2s/epoch - 501ms/step\n",
      "Epoch 2/20\n",
      "4/4 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000 - 265ms/epoch - 66ms/step\n",
      "Epoch 3/20\n",
      "4/4 - 0s - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.9434e-04 - val_accuracy: 1.0000 - 254ms/epoch - 63ms/step\n",
      "Epoch 4/20\n",
      "4/4 - 0s - loss: 7.5225e-04 - accuracy: 1.0000 - val_loss: 8.6387e-04 - val_accuracy: 1.0000 - 256ms/epoch - 64ms/step\n",
      "Epoch 5/20\n",
      "4/4 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - 252ms/epoch - 63ms/step\n",
      "Epoch 6/20\n",
      "4/4 - 0s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.7805e-04 - val_accuracy: 1.0000 - 264ms/epoch - 66ms/step\n",
      "Epoch 7/20\n",
      "4/4 - 0s - loss: 6.9973e-04 - accuracy: 1.0000 - val_loss: 2.7307e-05 - val_accuracy: 1.0000 - 297ms/epoch - 74ms/step\n",
      "Epoch 8/20\n",
      "4/4 - 1s - loss: 3.3942e-05 - accuracy: 1.0000 - val_loss: 6.5701e-05 - val_accuracy: 1.0000 - 532ms/epoch - 133ms/step\n",
      "Epoch 9/20\n",
      "4/4 - 1s - loss: 3.4820e-05 - accuracy: 1.0000 - val_loss: 5.7649e-04 - val_accuracy: 1.0000 - 538ms/epoch - 134ms/step\n",
      "Epoch 10/20\n",
      "4/4 - 0s - loss: 6.5249e-05 - accuracy: 1.0000 - val_loss: 1.2983e-04 - val_accuracy: 1.0000 - 488ms/epoch - 122ms/step\n",
      "Epoch 11/20\n",
      "4/4 - 1s - loss: 1.2954e-05 - accuracy: 1.0000 - val_loss: 1.5542e-05 - val_accuracy: 1.0000 - 545ms/epoch - 136ms/step\n",
      "Epoch 12/20\n",
      "4/4 - 0s - loss: 1.9049e-06 - accuracy: 1.0000 - val_loss: 3.8238e-06 - val_accuracy: 1.0000 - 487ms/epoch - 122ms/step\n",
      "Epoch 13/20\n",
      "4/4 - 1s - loss: 8.9772e-07 - accuracy: 1.0000 - val_loss: 1.6781e-06 - val_accuracy: 1.0000 - 522ms/epoch - 131ms/step\n",
      "Epoch 14/20\n",
      "4/4 - 1s - loss: 8.3446e-07 - accuracy: 1.0000 - val_loss: 1.1004e-06 - val_accuracy: 1.0000 - 568ms/epoch - 142ms/step\n",
      "Epoch 15/20\n",
      "4/4 - 1s - loss: 9.0258e-07 - accuracy: 1.0000 - val_loss: 9.1699e-07 - val_accuracy: 1.0000 - 562ms/epoch - 141ms/step\n",
      "Epoch 16/20\n",
      "4/4 - 0s - loss: 9.8773e-07 - accuracy: 1.0000 - val_loss: 8.3446e-07 - val_accuracy: 1.0000 - 405ms/epoch - 101ms/step\n",
      "Epoch 17/20\n",
      "4/4 - 0s - loss: 1.0340e-06 - accuracy: 1.0000 - val_loss: 8.0695e-07 - val_accuracy: 1.0000 - 488ms/epoch - 122ms/step\n",
      "Epoch 18/20\n",
      "4/4 - 1s - loss: 1.0340e-06 - accuracy: 1.0000 - val_loss: 7.7944e-07 - val_accuracy: 1.0000 - 515ms/epoch - 129ms/step\n",
      "Epoch 19/20\n",
      "4/4 - 1s - loss: 1.0048e-06 - accuracy: 1.0000 - val_loss: 7.6110e-07 - val_accuracy: 1.0000 - 577ms/epoch - 144ms/step\n",
      "Epoch 20/20\n",
      "4/4 - 0s - loss: 9.5854e-07 - accuracy: 1.0000 - val_loss: 7.7027e-07 - val_accuracy: 1.0000 - 455ms/epoch - 114ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "hist = classifier.fit(X_train, y_train, batch_size=16, epochs=20,\n",
    "                          shuffle=True, verbose=2, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c9eee",
   "metadata": {},
   "source": [
    "# Save Model weights and Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67f5c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights and architecture\n",
    "classifier.save_weights('model/model_weights.h5')\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6eba48",
   "metadata": {},
   "source": [
    "# Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eeb861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "f = open('model/history.pckl', 'wb')\n",
    "pickle.dump(hist.history, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
